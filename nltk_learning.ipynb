{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "id": "Niu-z0clKr59"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Reading training data from a file</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "7JYtAzKSO2Mx",
    "outputId": "15443fe8-ec23-437a-91c6-bcc71b7562ca"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('medium_articles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h3><i>Removing unnecessary data from the text dataset</i></h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Photo by Josh Riemer on Unsplash\\n\\nMerry Chri...</td>\n",
       "      <td>['Mental Health', 'Health', 'Psychology', 'Sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Your Brain On Coronavirus\\n\\nA guide to the cu...</td>\n",
       "      <td>['Mental Health', 'Coronavirus', 'Science', 'P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mind Your Nose\\n\\nHow smell training can chang...</td>\n",
       "      <td>['Biotechnology', 'Neuroscience', 'Brain', 'We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Passionate about the synergy between science a...</td>\n",
       "      <td>['Health', 'Neuroscience', 'Mental Health', 'P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You’ve heard of him, haven’t you? Phineas Gage...</td>\n",
       "      <td>['Brain', 'Health', 'Development', 'Psychology...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mentally, Young Adults Are Suffering Most From...</td>\n",
       "      <td>['Society', 'Mental Health', 'Health', 'Nonfic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Photo by Josh Riemer on Unsplash\\n\\nMerry Chri...   \n",
       "1  Your Brain On Coronavirus\\n\\nA guide to the cu...   \n",
       "2  Mind Your Nose\\n\\nHow smell training can chang...   \n",
       "3  Passionate about the synergy between science a...   \n",
       "4  You’ve heard of him, haven’t you? Phineas Gage...   \n",
       "5  Mentally, Young Adults Are Suffering Most From...   \n",
       "\n",
       "                                                tags  \n",
       "0  ['Mental Health', 'Health', 'Psychology', 'Sci...  \n",
       "1  ['Mental Health', 'Coronavirus', 'Science', 'P...  \n",
       "2  ['Biotechnology', 'Neuroscience', 'Brain', 'We...  \n",
       "3  ['Health', 'Neuroscience', 'Mental Health', 'P...  \n",
       "4  ['Brain', 'Health', 'Development', 'Psychology...  \n",
       "5  ['Society', 'Mental Health', 'Health', 'Nonfic...  "
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop('title', axis=1, inplace=True)\n",
    "data.drop('authors', axis=1, inplace=True)\n",
    "data.drop('timestamp', axis=1, inplace=True)\n",
    "data.drop('url', axis=1, inplace=True)\n",
    "\n",
    "data = data.dropna(subset = ['text'])\n",
    "data = data.iloc[:100]\n",
    "data[:6]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h3><i>Removing punctuation</i></h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = string.punctuation\n",
    "def remove_punc():\n",
    "    data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "    for index in range(0, len(data)):\n",
    "        for s in punctuation:\n",
    "            data.loc[index, 'text'] = data.loc[index, 'text'].replace(s, ' ')\n",
    "        data.loc[index, 'text'] = data.loc[index, 'text'].replace('\\n', ' ').replace('“', '').replace('”','').replace('—','').replace(\"’\",\"`\")\n",
    "remove_punc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'us' in stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h3><i>Spliting text</i></h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>photo by josh riemer on unsplash  merry christ...</td>\n",
       "      <td>['Mental Health', 'Health', 'Psychology', 'Sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>your brain on coronavirus  a guide to the curi...</td>\n",
       "      <td>['Mental Health', 'Coronavirus', 'Science', 'P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mind your nose  how smell training can change ...</td>\n",
       "      <td>['Biotechnology', 'Neuroscience', 'Brain', 'We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>passionate about the synergy between science a...</td>\n",
       "      <td>['Health', 'Neuroscience', 'Mental Health', 'P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you`ve heard of him  haven`t you  phineas gage...</td>\n",
       "      <td>['Brain', 'Health', 'Development', 'Psychology...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  photo by josh riemer on unsplash  merry christ...   \n",
       "1  your brain on coronavirus  a guide to the curi...   \n",
       "2  mind your nose  how smell training can change ...   \n",
       "3  passionate about the synergy between science a...   \n",
       "4  you`ve heard of him  haven`t you  phineas gage...   \n",
       "\n",
       "                                                tags  \n",
       "0  ['Mental Health', 'Health', 'Psychology', 'Sci...  \n",
       "1  ['Mental Health', 'Coronavirus', 'Science', 'P...  \n",
       "2  ['Biotechnology', 'Neuroscience', 'Brain', 'We...  \n",
       "3  ['Health', 'Neuroscience', 'Mental Health', 'P...  \n",
       "4  ['Brain', 'Health', 'Development', 'Psychology...  "
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [photo, by, josh, riemer, on, unsplash, merry,...\n",
      "1    [your, brain, on, coronavirus, a, guide, to, t...\n",
      "2    [mind, your, nose, how, smell, training, can, ...\n",
      "3    [passionate, about, the, synergy, between, sci...\n",
      "Name: vectors, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def split(data):\n",
    "    data['vectors'] = data['text'].apply(lambda row: row.split(' '))\n",
    "    for i in range (0,len(data)):\n",
    "        vectors = data.loc[i, 'vectors']\n",
    "        for word in vectors:\n",
    "            if not word.strip():\n",
    "                vectors.remove(word)\n",
    "        data.at[i, 'vectors'] = vectors\n",
    "\n",
    "split(data)\n",
    "print(data[0:4]['vectors'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h3><i>Removing stop words</i></h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=nltk.corpus.stopwords.words('english')\n",
    "stop_words = [word.replace(\"'\", \"`\") for word in stop_words]\n",
    "data['count'] = data['vectors'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'that`s' in stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords():\n",
    "    for i in range (0, len(data)):\n",
    "        words = data.loc[i, 'vectors']\n",
    "        removed_words = 0\n",
    "        length = len(words)\n",
    "        for index in range(0, length):\n",
    "            if words[index - removed_words] in stop_words:\n",
    "                words.remove(words[index - removed_words])\n",
    "                removed_words = removed_words + 1\n",
    "        data.at[i, 'vectors'] = words\n",
    "remove_stopwords()\n",
    "data['count'] = data['vectors'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h3><i>Stemming</i></h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "      <th>vectors</th>\n",
       "      <th>count</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>photo by josh riemer on unsplash  merry christ...</td>\n",
       "      <td>['Mental Health', 'Health', 'Psychology', 'Sci...</td>\n",
       "      <td>[photo, josh, riemer, unsplash, merry, christm...</td>\n",
       "      <td>450</td>\n",
       "      <td>[photo, josh, riemer, unsplash, merri, christm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  photo by josh riemer on unsplash  merry christ...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['Mental Health', 'Health', 'Psychology', 'Sci...   \n",
       "\n",
       "                                             vectors  count  \\\n",
       "0  [photo, josh, riemer, unsplash, merry, christm...    450   \n",
       "\n",
       "                                             stemmed  \n",
       "0  [photo, josh, riemer, unsplash, merri, christm...  "
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              stemmed  \\\n",
      "0   [photo, josh, riemer, unsplash, merri, christm...   \n",
      "1   [brain, coronaviru, guid, curiou, troubl, impa...   \n",
      "2   [mind, nose, smell, train, chang, brain, six, ...   \n",
      "3   [passion, synergi, scienc, technolog, provid, ...   \n",
      "4   [heard, phinea, gage, railroad, worker, surviv...   \n",
      "..                                                ...   \n",
      "95  [solitud, stigma, societi, harshli, judg, solo...   \n",
      "96  [think, work, googl, like, come, mind, legenda...   \n",
      "97  [j, k, rowling`, advic, writer, big, dream, si...   \n",
      "98  [septemb, 22, mark, begin, autumn, remind, won...   \n",
      "99  [mesensei, compani, design, creat, mobil, solu...   \n",
      "\n",
      "                                              vectors  \n",
      "0   [photo, josh, riemer, unsplash, merry, christm...  \n",
      "1   [brain, coronavirus, guide, curious, troubling...  \n",
      "2   [mind, nose, smell, training, change, brain, s...  \n",
      "3   [passionate, synergy, science, technology, pro...  \n",
      "4   [heard, phineas, gage, railroad, worker, survi...  \n",
      "..                                                ...  \n",
      "95  [solitude, stigma, society, harshly, judges, s...  \n",
      "96  [think, working, google, likely, comes, mind, ...  \n",
      "97  [j, k, rowling`s, advice, writers, big, dreams...  \n",
      "98  [september, 22, marked, beginning, autumn, rem...  \n",
      "99  [mesensei, company, designs, creates, mobile, ...  \n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def stem_text():\n",
    "    ps = nltk.PorterStemmer() \n",
    "    data['stemmed'] = data['vectors'].apply(lambda x: copy.deepcopy(x))\n",
    "    for index in range(0, len(data)):\n",
    "        words = data.loc[index, 'stemmed']\n",
    "        for i in range(0, len(words)):\n",
    "            words[i] = ps.stem(words[i])\n",
    "        data.at[index, 'stemmed'] = words\n",
    "stem_text()\n",
    "print(data[['stemmed', 'vectors']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h3><i>Lemmatizing</i></h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: sens, end: sen\n",
      "Start: sens, end: sen\n",
      "Start: sens, end: sen\n",
      "Start: pas, end: pa\n",
      "Start: pas, end: pa\n",
      "Start: pass, end: pas\n",
      "Start: pass, end: pas\n",
      "Start: cs, end: c\n",
      "Start: us, end: u\n",
      "Start: pas, end: pa\n",
      "Start: pass, end: pas\n",
      "Start: us, end: u\n",
      "Start: pas, end: pa\n",
      "Start: us, end: u\n",
      "Start: sens, end: sen\n",
      "Start: us, end: u\n",
      "Start: pas, end: pa\n",
      "Start: as, end: a\n",
      "Start: us, end: u\n",
      "Start: us, end: u\n"
     ]
    }
   ],
   "source": [
    "def lemmatize_text():\n",
    "    lm = nltk.WordNetLemmatizer() \n",
    "    data['lammatized'] = data['vectors'].apply(lambda x: copy.deepcopy(x))\n",
    "    for index in range(0, len(data)):\n",
    "        words = data.loc[index, 'lammatized']\n",
    "        for i in range(0, len(words)):\n",
    "            words[i] = lm.lemmatize(words[i])\n",
    "        data.at[index, 'lammatized'] = words\n",
    "lemmatize_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h1><strong>Vectorizing data</strong></h1><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h3><i>Count vectorising</i></h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_counts_stemmed = count_vect.fit_transform(data['stemmed'].apply(lambda x: ' '.join(x)))\n",
    "# X_counts_lemmatized = count_vect.fit_transform(data['lammatized'].apply(lambda x: ' '.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 6515)\n"
     ]
    }
   ],
   "source": [
    "print(X_counts_stemmed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "albanesiu\n"
     ]
    }
   ],
   "source": [
    "print(count_vect.get_feature_names_out()[345])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h3><i>N gramm vectorising</i></h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_count_vect = CountVectorizer(ngram_range = (2,3))\n",
    "ngram_lemmatized = n_count_vect.fit_transform(data['lammatized'].apply(lambda x: ' '.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 83266)\n",
      "['000 american' '000 american 700' '000 common' ... '⁸state ai ethic'\n",
      " '⁹insurance product' '⁹insurance product ¹⁰data']\n"
     ]
    }
   ],
   "source": [
    "print(ngram_lemmatized.shape)\n",
    "print(n_count_vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>83256</th>\n",
       "      <th>83257</th>\n",
       "      <th>83258</th>\n",
       "      <th>83259</th>\n",
       "      <th>83260</th>\n",
       "      <th>83261</th>\n",
       "      <th>83262</th>\n",
       "      <th>83263</th>\n",
       "      <th>83264</th>\n",
       "      <th>83265</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 83266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0      1      2      3      4      5      6      7      8      9      ...  \\\n",
       "0       0      0      0      0      0      0      0      0      0      0  ...   \n",
       "1       0      0      0      0      0      0      0      0      0      0  ...   \n",
       "2       0      0      0      0      0      0      0      0      0      0  ...   \n",
       "3       0      0      0      0      0      0      0      0      0      0  ...   \n",
       "4       0      0      0      0      0      0      0      0      0      0  ...   \n",
       "..    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  ...   \n",
       "95      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "96      0      0      0      0      0      0      1      1      0      0  ...   \n",
       "97      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "98      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "99      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "\n",
       "    83256  83257  83258  83259  83260  83261  83262  83263  83264  83265  \n",
       "0       0      0      0      0      0      0      0      0      0      0  \n",
       "1       0      0      0      0      0      0      0      0      0      0  \n",
       "2       0      0      0      0      0      0      0      0      0      0  \n",
       "3       0      0      0      0      0      0      0      0      0      0  \n",
       "4       0      0      0      0      0      0      0      0      0      0  \n",
       "..    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "95      0      0      0      0      0      0      0      0      0      0  \n",
       "96      0      0      0      0      0      0      0      0      0      0  \n",
       "97      0      0      0      0      0      0      0      0      0      0  \n",
       "98      0      0      0      0      0      0      0      0      0      0  \n",
       "99      0      0      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[100 rows x 83266 columns]"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(ngram_lemmatized.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h3><i>Frequency weighting</i></h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect_stemmed = TfidfVectorizer()\n",
    "X_tfidf_stem = tfidf_vect_stemmed.fit_transform(data['stemmed'].apply(lambda x: ' '.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 6515)\n",
      "['000' '00041' '025' ... '⁷ai' '⁸state' '⁹insur']\n"
     ]
    }
   ],
   "source": [
    "print(X_tfidf_stem.shape)\n",
    "print(tfidf_vect_stemmed.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6505</th>\n",
       "      <th>6506</th>\n",
       "      <th>6507</th>\n",
       "      <th>6508</th>\n",
       "      <th>6509</th>\n",
       "      <th>6510</th>\n",
       "      <th>6511</th>\n",
       "      <th>6512</th>\n",
       "      <th>6513</th>\n",
       "      <th>6514</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028749</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.017571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013310</td>\n",
       "      <td>0.01931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6515 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2     3     4     5     6         7        8     9     \\\n",
       "0   0.000000   0.0   0.0   0.0   0.0   0.0   0.0  0.028749  0.00000   0.0   \n",
       "1   0.000000   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  0.00000   0.0   \n",
       "2   0.000000   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  0.00000   0.0   \n",
       "3   0.000000   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  0.00000   0.0   \n",
       "4   0.000000   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  0.00000   0.0   \n",
       "..       ...   ...   ...   ...   ...   ...   ...       ...      ...   ...   \n",
       "95  0.000000   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  0.00000   0.0   \n",
       "96  0.017571   0.0   0.0   0.0   0.0   0.0   0.0  0.013310  0.01931   0.0   \n",
       "97  0.000000   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  0.00000   0.0   \n",
       "98  0.000000   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  0.00000   0.0   \n",
       "99  0.000000   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  0.00000   0.0   \n",
       "\n",
       "    ...  6505  6506  6507  6508  6509  6510  6511  6512  6513  6514  \n",
       "0   ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "..  ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "95  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "96  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "97  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "98  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "99  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[100 rows x 6515 columns]"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_tfidf_stem.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
